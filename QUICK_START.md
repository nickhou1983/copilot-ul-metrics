# GitHub Copilot User Level Metrics - å¿«é€Ÿå¼€å§‹

## ðŸš€ å¿«é€Ÿä¸Šæ‰‹

### æ­¥éª¤ 1: è½¬æ¢ JSON åˆ° CSV

```bash
# è½¬æ¢ JSON æ–‡ä»¶ä¸º CSVï¼ˆç”Ÿæˆæ‰€æœ‰ç»´åº¦ï¼‰
python3 json_to_csv.py your_data.json

# æˆ–æŒ‡å®šè¾“å‡ºç›®å½•
python3 json_to_csv.py your_data.json -o ./output
```

è¿™å°†ç”Ÿæˆ 6 ä¸ª CSV æ–‡ä»¶ï¼š
- âœ… `*_user_summary.csv` - ç”¨æˆ·æ€»ä½“æŒ‡æ ‡
- âœ… `*_by_ide.csv` - IDE ç»´åº¦ç»Ÿè®¡
- âœ… `*_by_feature.csv` - åŠŸèƒ½ç»´åº¦ç»Ÿè®¡
- âœ… `*_by_language_feature.csv` - è¯­è¨€+åŠŸèƒ½ç»´åº¦
- âœ… `*_by_language_model.csv` - è¯­è¨€+æ¨¡åž‹ç»´åº¦
- âœ… `*_by_model_feature.csv` - æ¨¡åž‹+åŠŸèƒ½ç»´åº¦

### æ­¥éª¤ 2: å®‰è£…åˆ†æžå·¥å…·ä¾èµ–ï¼ˆå¯é€‰ï¼‰

å¦‚æžœéœ€è¦ä½¿ç”¨æ•°æ®åˆ†æžè„šæœ¬ï¼š

```bash
pip3 install -r requirements.txt
```

### æ­¥éª¤ 3: è¿è¡Œæ•°æ®åˆ†æž

```bash
python3 analyze_metrics.py
```

è¿™å°†ç”Ÿæˆå®Œæ•´çš„åˆ†æžæŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š
- ðŸ“Š ç”¨æˆ·æ´»è·ƒåº¦ç»Ÿè®¡
- ðŸ† TOP 10 æ´»è·ƒç”¨æˆ·
- âš¡ å„åŠŸèƒ½ä½¿ç”¨æƒ…å†µ
- ðŸ”¤ ç¼–ç¨‹è¯­è¨€åˆ†å¸ƒ
- ðŸ› ï¸ IDE ä½¿ç”¨ç»Ÿè®¡
- ðŸ¤– AI æ¨¡åž‹æ•ˆæžœå¯¹æ¯”

## ðŸ“Š ä½¿ç”¨ Excel åˆ†æž

ç”Ÿæˆçš„ CSV æ–‡ä»¶å¯ä»¥ç›´æŽ¥åœ¨ Excel ä¸­æ‰“å¼€ï¼š

1. åŒå‡»æ‰“å¼€ CSV æ–‡ä»¶
2. ä½¿ç”¨"æ’å…¥" > "æ•°æ®é€è§†è¡¨"åˆ›å»ºåˆ†æžè§†å›¾
3. åˆ›å»ºå›¾è¡¨è¿›è¡Œå¯è§†åŒ–

## ðŸŽ¯ å¸¸è§ä½¿ç”¨åœºæ™¯

### åœºæ™¯ 1: æŸ¥çœ‹ç‰¹å®šç”¨æˆ·çš„ä½¿ç”¨æƒ…å†µ

åœ¨ Excel æˆ– Python ä¸­ç­›é€‰ç‰¹å®šçš„ `user_login`ï¼š

```python
import pandas as pd
df = pd.read_csv('*_user_summary.csv')
user_data = df[df['user_login'] == 'username']
print(user_data)
```

### åœºæ™¯ 2: åˆ†æžæŸä¸ªæ—¥æœŸèŒƒå›´çš„æ•°æ®

```python
df['day'] = pd.to_datetime(df['day'])
sept_data = df[(df['day'] >= '2025-09-01') & (df['day'] <= '2025-09-30')]
print(f"9æœˆæ€»ä»£ç ç”Ÿæˆæ¬¡æ•°: {sept_data['code_generation_activity_count'].sum()}")
```

### åœºæ™¯ 3: å¯¹æ¯”ä¸åŒç¼–ç¨‹è¯­è¨€çš„æŽ¥å—çŽ‡

```python
lang_df = pd.read_csv('*_by_language_feature.csv')
lang_stats = lang_df.groupby('language').agg({
    'code_generation_activity_count': 'sum',
    'code_acceptance_activity_count': 'sum'
})
lang_stats['acceptance_rate'] = (
    lang_stats['code_acceptance_activity_count'] / 
    lang_stats['code_generation_activity_count'] * 100
)
print(lang_stats.sort_values('acceptance_rate', ascending=False))
```

### åœºæ™¯ 4: åˆ†æžåŠŸèƒ½é‡‡ç”¨è¶‹åŠ¿

```python
feature_df = pd.read_csv('*_by_feature.csv')
feature_df['day'] = pd.to_datetime(feature_df['day'])
daily_usage = feature_df.groupby(['day', 'feature'])['code_generation_activity_count'].sum().unstack()
daily_usage.plot(kind='line', figsize=(12, 6), title='åŠŸèƒ½ä½¿ç”¨è¶‹åŠ¿')
```

## ðŸ“ é¡¹ç›®æ–‡ä»¶è¯´æ˜Ž

| æ–‡ä»¶ | è¯´æ˜Ž | ä¾èµ– |
|------|------|------|
| `json_to_csv.py` | JSON è½¬ CSV è½¬æ¢å™¨ | æ— ï¼ˆä»…Pythonæ ‡å‡†åº“ï¼‰ |
| `analyze_metrics.py` | æ•°æ®åˆ†æžç¤ºä¾‹è„šæœ¬ | pandas |
| `requirements.txt` | Python ä¾èµ–åˆ—è¡¨ | - |
| `README.md` | å®Œæ•´çš„æ–‡æ¡£å’ŒæŒ‡æ ‡è¯´æ˜Ž | - |
| `QUICK_START.md` | æœ¬å¿«é€Ÿå…¥é—¨æŒ‡å— | - |

## ðŸ’¡ æç¤º

- CSV æ–‡ä»¶ä½¿ç”¨ UTF-8-BOM ç¼–ç ï¼Œå¯ä»¥åœ¨ Excel ä¸­æ­£ç¡®æ˜¾ç¤ºä¸­æ–‡
- `json_to_csv.py` æ— éœ€å®‰è£…ä»»ä½•ä¾èµ–å³å¯ä½¿ç”¨
- `analyze_metrics.py` éœ€è¦å®‰è£… pandasï¼Œä½†æä¾›äº†æ›´ä¸°å¯Œçš„åˆ†æžåŠŸèƒ½
- æ‰€æœ‰è„šæœ¬éƒ½æ”¯æŒ `--help` å‚æ•°æŸ¥çœ‹è¯¦ç»†ä½¿ç”¨è¯´æ˜Ž

## ðŸ”— æ›´å¤šä¿¡æ¯

è¯¦ç»†çš„æŒ‡æ ‡è¯´æ˜Žå’Œæ•°æ®ç»“æž„è¯·å‚è€ƒ [README.md](README.md)
